{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial import ConvexHull\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "\n",
    "def get_commont_vertex(edge_pair):\n",
    "    a = edge_pair[:, 0] == edge_pair[:, 1]\n",
    "    b = edge_pair[:, 0] == torch.flip(edge_pair[:, 1], dims=[1])\n",
    "\n",
    "    return edge_pair[:, 0][a + b]\n",
    "\n",
    "class Non(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Non, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def adjacency_matrix(vertices, faces):\n",
    "    B, N, D = vertices.shape\n",
    "\n",
    "    halfedges = torch.tensor(list(combinations(range(D), 2)))\n",
    "    edges = torch.cat([halfedges, torch.flip(halfedges,dims=[1])], dim=0)\n",
    "\n",
    "\n",
    "    A = torch.zeros(1, N, N, device=faces.device)\n",
    "\n",
    "    all_edges = faces[:, :, edges].long()\n",
    "    all_edges = all_edges.view(1, -1, 2)\n",
    "    A[0, all_edges[0, :, 0], all_edges[0, :, 1]] = 1 \n",
    "    D = torch.diag(1 / torch.squeeze(torch.sum(A, dim=1)))[None]\n",
    "\n",
    "    A = A.repeat(B, 1, 1)\n",
    "    D = D.repeat(B, 1, 1)\n",
    "\n",
    "    return A, D \n",
    "\n",
    "\n",
    "def adaptive_unpool(vertices, faces_prev, sphere_vertices, latent_features, N_prev):\n",
    "    print(\"vertices\", vertices.shape)\n",
    "    vertices_primary = vertices[0,:N_prev, :]\n",
    "    #vertices_primary = vertices[0, :, :] #moja zmiana\n",
    "    print(\"vertices_primary\", vertices_primary.shape)\n",
    "    vertices_secondary = vertices[0,N_prev:, :]\n",
    "    #vertices_secondary = vertices[0, :, :] #moja zmiana\n",
    "    faces_primary = faces_prev[0]\n",
    "    print(\"vertices_secondary\", vertices_secondary.shape)\n",
    "    sphere_vertices_primary = sphere_vertices[0,:N_prev]\n",
    "    sphere_vertices_secondary = sphere_vertices[0,N_prev:]\n",
    "\n",
    "    if latent_features is not None:\n",
    "        latent_features_primary = latent_features[0,:N_prev]\n",
    "        latent_features_secondary = latent_features[0,N_prev:]\n",
    "\n",
    "    face_count, _ = faces_primary.shape\n",
    "    vertices_count = len(vertices_primary)\n",
    "    edge_combinations_3 = torch.tensor(list(combinations(range(3), 2)), device = vertices.device)\n",
    "    print(\"faces primary\", faces_primary.shape)\n",
    "    edges = faces_primary[:, edge_combinations_3]\n",
    "    print(edges[0:10])\n",
    "    print(\"edges\", edges.shape)\n",
    "    unique_edges = edges.view(-1, 2)\n",
    "    print(\"unique_edges 1\", unique_edges.shape)\n",
    "    unique_edges, _ = torch.sort(unique_edges, dim=1)\n",
    "    print(\"unique_edges 2\", unique_edges.shape)\n",
    "    unique_edges, unique_edge_indices = torch.unique(unique_edges, return_inverse=True, dim=0)\n",
    "    print(unique_edges[0:10])\n",
    "    print(\"unique_edges 3\", unique_edges.shape)\n",
    "    face_edges_primary = vertices_primary[unique_edges]\n",
    "    print(\"face_edges\", face_edges_primary.shape)\n",
    "    print(type(face_edges_primary))\n",
    "\n",
    "    a = face_edges_primary[:,0]\n",
    "    b = face_edges_primary[:,1]\n",
    "    v = vertices_secondary\n",
    "    print(\"a\", a.shape)\n",
    "    print(\"b\", b.shape)\n",
    "    print(\"v\", v.shape) \n",
    "\n",
    "    va = v - a\n",
    "    vb = v - b\n",
    "    ba = b - a\n",
    "\n",
    "    cond1 = (va * ba).sum(1)\n",
    "    norm1 = torch.norm(va, dim=1)\n",
    "\n",
    "    cond2 = (vb * ba).sum(1)\n",
    "    norm2 = torch.norm(vb, dim=1)\n",
    "\n",
    "    dist = torch.norm(torch.cross(va, ba), dim=1)/torch.norm(ba, dim=1)\n",
    "    dist[cond1 < 0] = norm1[cond1 < 0]\n",
    "    dist[cond2 < 0] = norm2[cond2 < 0]\n",
    "\n",
    "    sorted_, _ = torch.sort(dist)\n",
    "    threshold = sorted_[int(0.3*len(sorted_))] \n",
    "\n",
    "    vertices_needed = vertices_secondary[dist > threshold]\n",
    "    \n",
    "    sphere_vertices_needed = sphere_vertices_secondary[dist > threshold] \n",
    "    if latent_features is not None:\n",
    "        latent_features_needed = latent_features_secondary[dist > threshold]\n",
    "\n",
    "    vertices = torch.cat([vertices_primary,vertices_needed],dim=0)[None]\n",
    "    if latent_features is not None:\n",
    "        latent_features = torch.cat([latent_features_primary,latent_features_needed],dim=0)[None]\n",
    "\n",
    "    sphere_vertices = torch.cat([sphere_vertices_primary,sphere_vertices_needed],dim=0) \n",
    "    sphere_vertices = sphere_vertices/torch.sqrt(torch.sum(sphere_vertices**2,dim=1)[:,None])\n",
    "    hull = ConvexHull(sphere_vertices.data.cpu().numpy())  \n",
    "    faces = torch.from_numpy(hull.simplices).long().cuda()[None] \n",
    "\n",
    "    sphere_vertices = sphere_vertices[None]  \n",
    "\n",
    "    return vertices, faces, latent_features, sphere_vertices\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    __constants__ = ['bias', 'in_features', 'out_features']\n",
    "\n",
    "    def __init__(self, in_features, out_features, batch_norm=False):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        self.neighbours_fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "        self.bc = nn.BatchNorm1d(out_features) if batch_norm else Non()\n",
    "\n",
    "    def forward(self, input, A, Dinv, vertices, faces):\n",
    "\n",
    "        # coeff = torch.bmm(torch.bmm(Dsqrtinv, A), Dsqrtinv)\n",
    "        coeff = torch.bmm(Dinv, A) # row normalization, zmienione z bmm na mm ze względu na batch 1\n",
    "        #coeff ma na celu wyrownanie wpływu wierzchołków o większej liczbie sąsiadów na deformację, dlatego to nie ejst samo A, tylko pomnożone przez Dinv\n",
    "        y = self.fc(input) #to jest zwykła transformacja liniowa\n",
    "        y_neightbours = torch.bmm(coeff, input)#zmienione bmm na matmul, ze względu na batch 1.\n",
    "        #linijka wyżej mnoży współczynnik z cechami. Współczynnik jest reprezentacją connectivity w meshu deformowanym, więc to jest przerzucenie cech na siatkę\n",
    "        y_neightbours = self.neighbours_fc(y_neightbours)\n",
    " \n",
    " \n",
    "        # y_neightbours = self.bc(y_neightbours.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        y = y + y_neightbours\n",
    "        # y = self.bc(y.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}'.format(\n",
    "            self.in_features, self.out_features is not None\n",
    "        )\n",
    "    \n",
    "\n",
    "class Feature2VertexLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden_layer_count, batch_norm=False):\n",
    "        super(Feature2VertexLayer, self).__init__()\n",
    "        self.gconv = []\n",
    "        for i in range(hidden_layer_count, 1, -1):\n",
    "            self.gconv += [GraphConv(i * in_features // hidden_layer_count, (i-1) * in_features // hidden_layer_count, batch_norm)]\n",
    "        self.gconv_layer = nn.Sequential(*self.gconv)\n",
    "        self.gconv_last = GraphConv(in_features // hidden_layer_count, 3, batch_norm)\n",
    "\n",
    "    def forward(self, features, adjacency_matrix, degree_matrix, vertices, faces):\n",
    "        for gconv_hidden in self.gconv:\n",
    "            features = F.relu(gconv_hidden(features, adjacency_matrix, degree_matrix,vertices,faces))\n",
    "        return self.gconv_last(features, adjacency_matrix, degree_matrix,vertices,faces)\n",
    "\n",
    "class Features2Features(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, hidden_layer_count=2, graph_conv=GraphConv):\n",
    "        super(Features2Features, self).__init__()\n",
    "\n",
    "        self.gconv_first = graph_conv(in_features, out_features)\n",
    "        gconv_hidden = []\n",
    "        for i in range(hidden_layer_count):\n",
    "            gconv_hidden += [graph_conv(out_features, out_features)]\n",
    "        self.gconv_hidden = nn.Sequential(*gconv_hidden)\n",
    "        self.gconv_last = graph_conv(out_features, out_features)\n",
    "\n",
    "    def forward(self, features, adjacency_matrix, degree_matrix, vertices, faces):\n",
    "        features = F.relu(self.gconv_first(features, adjacency_matrix, degree_matrix, vertices,faces))\n",
    "        for gconv_hidden in self.gconv_hidden:\n",
    "            features = F.relu(gconv_hidden(features, adjacency_matrix, degree_matrix, vertices,faces))\n",
    "        return self.gconv_last(features, adjacency_matrix, degree_matrix, vertices, faces)\n",
    "\n",
    "def uniform_unpool(vertices_, faces_, identical_face_batch=True):\n",
    "    if vertices_ is None:\n",
    "        return None, None\n",
    "    batch_size , _, _ = vertices_.shape\n",
    "    new_faces_all = []\n",
    "    new_vertices_all = []\n",
    "\n",
    "    for vertices, faces in zip(vertices_, faces_):\n",
    "        face_count, _ = faces.shape\n",
    "        vertices_count = len(vertices)\n",
    "        edge_combinations_3 = torch.tensor(list(combinations(range(3), 2)))\n",
    "        edges = faces[:, edge_combinations_3]\n",
    "        unique_edges = edges.view(-1, 2)\n",
    "        unique_edges, _ = torch.sort(unique_edges, dim=1)\n",
    "        unique_edges, unique_edge_indices = torch.unique(unique_edges, return_inverse=True, dim=0)\n",
    "        face_edges = vertices[unique_edges]\n",
    "\n",
    "        ''' Computer new vertices '''\n",
    "        new_vertices = torch.mean(face_edges, dim=1)\n",
    "        new_vertices = torch.cat([vertices, new_vertices], dim=0)  # <----------------------- new vertices + old vertices\n",
    "        new_vertices_all += [new_vertices[None]]\n",
    "\n",
    "        ''' Compute new faces '''\n",
    "        corner_faces = []\n",
    "        middle_face = []\n",
    "        for j, combination in enumerate(edge_combinations_3):\n",
    "            edge_pair = edges[:, combination]\n",
    "            common_vertex = get_commont_vertex(edge_pair)\n",
    "\n",
    "            new_vertex_1 = unique_edge_indices[torch.arange(0, 3 * face_count, 3) + combination[0]] + vertices_count\n",
    "            new_vertex_2 = unique_edge_indices[torch.arange(0, 3 * face_count, 3) + combination[1]] + vertices_count\n",
    "\n",
    "            middle_face += [new_vertex_1[:, None], new_vertex_2[:, None]]\n",
    "            corner_faces += [torch.cat([common_vertex[:, None], new_vertex_1[:, None], new_vertex_2[:, None]], dim=1)]\n",
    "\n",
    "        corner_faces = torch.cat(corner_faces, dim=0)\n",
    "        middle_face = torch.cat(middle_face, dim=1)\n",
    "        middle_face = torch.unique(middle_face, dim=1)\n",
    "        new_faces_all += [torch.cat([corner_faces, middle_face], dim=0)[None]]  # new faces-3\n",
    "\n",
    "        if identical_face_batch:\n",
    "            new_vertices_all = new_vertices_all[0].repeat(batch_size, 1, 1)\n",
    "            new_faces_all = new_faces_all[0].repeat(batch_size, 1, 1)\n",
    "            break\n",
    "\n",
    "    return new_vertices_all, new_faces_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"latent_features_count\": [256, 32],\n",
    "    \"graph_conv_layer_count\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(MeshDecoder, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.graph_conv_net = Features2Features(config[\"latent_features_count\"][0], config[\"latent_features_count\"][1], hidden_layer_count=config[\"graph_conv_layer_count\"])\n",
    "        self.feature_to_vertex = Feature2VertexLayer(config[\"latent_features_count\"][1], 2)\n",
    "\n",
    "    def forward(self, vertices, faces, latent_features):\n",
    "\n",
    "        #A, D = adjacency_matrix(vertices, faces) #jeśli dobrze rozumiem działanie tej funkcji?\n",
    "        print(\"przed unpool\",vertices.shape)\n",
    "        _, N_prev, _ = vertices.shape \n",
    "        #to jest grafowa CNN do przekształcenia cech z enkodera do cech które przyjmie F2V\n",
    "        #latent_features = self.graph_conv_net(latent_features, A, D, vertices, faces)\n",
    "        vertices, faces_ = uniform_unpool(vertices, faces)  \n",
    "        latent_features, _ = uniform_unpool(latent_features, faces)\n",
    "        faces = faces_\n",
    "        print(\"po unpool\",vertices.shape)\n",
    "        print(vertices.shape)\n",
    "        A, D = adjacency_matrix(vertices, faces)\n",
    "        updated_latent_features = self.graph_conv_net(latent_features, A, D, vertices, faces)\n",
    "\n",
    "        #być może latent_features = torch.cat()\n",
    "\n",
    "        #f2v - obliczenie wektorów deformacji z cech, czyli przeniesienie na przestrzeń wierzchołków? współrzędnych?\n",
    "        deformation_vectors = self.feature_to_vertex(updated_latent_features, A, D, vertices, faces)\n",
    "\n",
    "        #deformacja siatki - przesunięcie o wektor wierzchołków. Faces się nie zmieniają, bo one wskazują wierzchołki, nie mają współrzędnych\n",
    "        deformed_vertices = vertices + deformation_vectors\n",
    "        print(\"latent feas\", updated_latent_features.shape)\n",
    "\n",
    "        #unpooling - upsampling, może być uniform, ale adaptive jest lepszy, bo nie dodaje niepotrzebnych wierzchołków na płaskich przestrzeniach.\n",
    "        #upsampled_vertices, upsampled_faces = adaptive_unpool(vertices, faces, deformed_vertices, latent_features, N_prev)\n",
    "        upsampled_vertices = deformed_vertices\n",
    "        upsampled_faces = faces\n",
    "        return upsampled_vertices, upsampled_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1250, 256])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stl import mesh\n",
    "\n",
    "SPHERE_PATH = \"Sphere.stl\"\n",
    "\n",
    "vertices = np.load(\"dataset/val/data/b1900015/vertices.npy\")\n",
    "faces = np.load(\"dataset/val/data/b1900015/faces.npy\")\n",
    "\n",
    "def copy_data(data):\n",
    "\n",
    "    output = torch.zeros(1, 1250, 256)\n",
    "    for i in range(1250):\n",
    "        output[:, i, :] = data\n",
    "    return output\n",
    "\n",
    "latent_features = torch.rand(1, 256)\n",
    "latent_features = copy_data(latent_features)\n",
    "print(latent_features.shape)\n",
    "\n",
    "loaded_mesh = mesh.Mesh.from_file(SPHERE_PATH)\n",
    "vertex_dict = {} #for storing vertices and their indices, helps to avoid duplicating the same vertices\n",
    "sphere_vertices = np.empty((0, 3), dtype=float) #array of vertices - shape (n, 3), stores x, y, z coordinates of each vertex\n",
    "sphere_faces = [] #array of faces - shape (n, 3), stores indices of vertices in each face\n",
    "\n",
    "for vectors in loaded_mesh.vectors:\n",
    "        for vertex in vectors:\n",
    "            vertex_tuple = tuple(vertex)\n",
    "\n",
    "            if vertex_tuple in vertex_dict:\n",
    "                index = vertex_dict[vertex_tuple]\n",
    "            else:\n",
    "                index = len(sphere_vertices)\n",
    "                sphere_vertices = np.append(sphere_vertices, [vertex], axis=0)\n",
    "                vertex_dict[vertex_tuple] = index\n",
    "\n",
    "        sphere_faces.append([vertex_dict[tuple(vertex)] for vertex in vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "przed unpool torch.Size([1, 1250, 3])\n",
      "po unpool torch.Size([1, 4994, 3])\n",
      "torch.Size([1, 4994, 3])\n",
      "latent feas torch.Size([1, 4994, 32])\n"
     ]
    }
   ],
   "source": [
    "sphere_vertices, sphere_faces = torch.tensor(sphere_vertices), torch.tensor(sphere_faces)\n",
    "vertices, faces = torch.tensor(vertices), torch.tensor(faces)\n",
    "\n",
    "sphere_faces = sphere_faces.unsqueeze(0)\n",
    "sphere_vertices = sphere_vertices.unsqueeze(0)\n",
    "\n",
    "decoder = MeshDecoder(config)\n",
    "decoder.eval()\n",
    "with torch.no_grad():\n",
    "    deformed_vertices, deformed_faces = decoder(sphere_vertices, sphere_faces, latent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4994, 3])\n",
      "torch.Size([1, 9984, 3])\n"
     ]
    }
   ],
   "source": [
    "print(deformed_vertices.shape)\n",
    "print(deformed_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1250, 3])\n",
      "torch.Size([1, 2496, 3])\n"
     ]
    }
   ],
   "source": [
    "print(sphere_vertices.shape)\n",
    "print(sphere_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stl import mesh\n",
    "\n",
    "def save_mesh_to_stl(deformed_vertices, faces, stl_filename):\n",
    "    # Przygotuj obiekt STL\n",
    "    mesh_data = mesh.Mesh(np.zeros(len(faces[0]), dtype=mesh.Mesh.dtype))\n",
    "\n",
    "    for i in range(len(faces[0])):\n",
    "        for j in range(3):\n",
    "            mesh_data.vectors[i][j] = deformed_vertices[0][faces[0][i][j]]\n",
    "    # Zapisz obiekt STL do pliku\n",
    "    mesh_data.save(stl_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "vtcs = torch.load(\"vertices_34\")\n",
    "fcs = torch.load(\"faces_34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = vtcs.detach().numpy()\n",
    "faces = fcs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mesh_to_stl(vertices, faces, \"test.stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
